{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b7032d01",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from keras_preprocessing.image import load_img, img_to_array\n",
    "from tensorflow.keras import backend as K\n",
    "import tensorflow.keras as tk\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.datasets import mnist, fashion_mnist,cifar10\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers import Conv2D, Dense, MaxPooling2D, Flatten, BatchNormalization,Dropout\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from matplotlib import pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0ca46e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "ls data/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccba5674",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X = []\n",
    "y = []\n",
    "classes = ['Blue_mug', 'mobile', 'Red_mug', 'Rose', 'empty', 'apple', 'biketool_mm', 'bodycream_test_ss', 'bodycream_train_ss', 'Bottle_gk',\n",
    "          'bottle_mw_test', 'bottle_mw_train', 'bottle_rbk','bottle_test_ss', 'bottle_train_ss', 'chris_bottle', 'chris_empty', 'crista_bottle',\n",
    "          'empty_crista', 'helge_scarf', 'helge_empty', 'plant_rbk', 'moritz_bottle','lighter_mm','him_teacup', 'helge_mouse',\n",
    "          'headphone_rbk','empty_train_ss', 'empty_train_ss', 'empty_crista', 'Naz_bottle']\n",
    "\n",
    "base_path = '.\\\\data\\\\'\n",
    "\n",
    "for i, target in enumerate(classes):\n",
    "    files = os.listdir(base_path+target)\n",
    "    for file in files:\n",
    "        # check if the file is a valid image file\n",
    "        if file.endswith('.jpg') or file.endswith('.jpeg') or file.endswith('.png'):\n",
    "            full_path=  base_path+target+ f'\\\\{file}'\n",
    "            print(full_path)\n",
    "            img =  load_img(full_path, target_size=(224, 224))\n",
    "            # append the array to X\n",
    "            img_array = img_to_array(img)\n",
    "            X.append(img_array)\n",
    "            y.append(i)\n",
    "\n",
    "X = np.array(X)\n",
    "y = np.array(y)\n",
    "\n",
    "# shuffle the data\n",
    "shuffler = np.random.permutation(len(X))\n",
    "X = X[shuffler]\n",
    "y = y[shuffler]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f9ad34f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into training and testing sets\n",
    "split_index = int(0.8 * len(X))\n",
    "X_train, X_test = X[:split_index], X[split_index:]\n",
    "y_train, y_test = y[:split_index], y[split_index:]\n",
    "\n",
    "# Convert labels to one-hot encoding\n",
    "num_classes = len(classes)\n",
    "y_train_one_hot = to_categorical(y_train, num_classes=num_classes)\n",
    "y_test_one_hot = to_categorical(y_test, num_classes=num_classes)\n",
    "\n",
    "# Define the model architecture\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, (3, 3), activation='relu', input_shape=(28, 28, 3)))\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(X_train, y_train_one_hot, epochs=10, validation_split=0.2)\n",
    "\n",
    "# Evaluate the model\n",
    "test_loss, test_acc = model.evaluate(X_test, y_test_one_hot)\n",
    "print('Test accuracy:', test_acc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59ece474",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape, X_test.shape, y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d0b29d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "history.history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5110c7c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot loss and accuracy curves\n",
    "pd.DataFrame(data=history.history).plot()\n",
    "plt.grid(True)\n",
    "plt.xlabel('epochs')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d6721f8",
   "metadata": {},
   "source": [
    "# To feed the images in a CNN we need to reshape our X data to the format \n",
    "# (batch/sample, width, heigth, channels):\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db51cb1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Xtrain = X_train.reshape(1552, 28, 28,3)\n",
    "#Xtest = X_test.reshape(389, 28, 28,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "233d9bec",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75ec1449",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(X_train[0].astype('uint8'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cec2d7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the train images  with the labels\n",
    "plt.figure(figsize=(16,16))\n",
    "for i in range(25):\n",
    "    plt.subplot(5, 5, i+1,title=f'Number: {y_train[i]}')\n",
    "    plt.imshow(Xtrain[i].astype('uint8'),cmap='gray')\n",
    "    plt.axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daa9d7a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The labels are 10 numbers (0...9) we transform it into 10 classes \n",
    "# ytrain, ytest from number to categorical/dummies\n",
    "\n",
    "ytrain_cat = to_categorical(y_train)\n",
    "ytest_cat = to_categorical(y_train)\n",
    "# Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0fbb7e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "ytrain_cat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c7d4651",
   "metadata": {},
   "outputs": [],
   "source": [
    "ytrain_cat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1940bf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from categorical to number\n",
    "np.argmax(ytrain_cat,axis=1),np.argmax(ytest_cat,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40c66fee",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('After preprocessing also y:\\n')\n",
    "print('Xtrain shape:', Xtrain.shape)\n",
    "print(Xtrain.shape[0], 'train samples')\n",
    "print(Xtest.shape[0], 'test samples')\n",
    "print(Xtrain[0].shape, 'image shape')\n",
    "print('ytrain cat shape:', ytrain_cat.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7dfbfdd",
   "metadata": {},
   "source": [
    "## LeNet-5 in Keras\n",
    "\n",
    "Implement LeNet-5 architecture from above.\n",
    "\n",
    "Use relu activation function for convolutional and fully-connected (dense) layers, and softmax for the output layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a4509b8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import keras.backend as K\n",
    "import tensorflow as tf\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "K.clear_session()\n",
    "\n",
    "# Load dataset\n",
    "# Assuming Xtrain and ytrain are already loaded\n",
    "\n",
    "# Convert ytrain to one-hot encoded format\n",
    "ytrain_cat = to_categorical(y_train)\n",
    "\n",
    "# Define model architecture\n",
    "model =  tf.keras.Sequential([\n",
    "    # Convolutional layers\n",
    "    Conv2D(filters=6, kernel_size=(5,5), strides=(1,1), padding='valid',\n",
    "           activation='relu', input_shape=(28,28,3),\n",
    "           kernel_initializer='glorot_normal', bias_initializer='zeros'),\n",
    "    MaxPooling2D(pool_size=(2,2), strides=(2,2), padding='valid'),\n",
    "    Conv2D(filters=16, kernel_size=(3,3), strides=(1,1), padding='valid',\n",
    "           activation='relu', kernel_initializer='glorot_normal', bias_initializer='zeros'),\n",
    "    MaxPooling2D(pool_size=(2,2), strides=(2,2), padding='valid'),\n",
    "    # Fully connected layers\n",
    "    Flatten(),\n",
    "    Dense(units=120, activation='relu', kernel_initializer='glorot_normal', bias_initializer='zeros'),\n",
    "    Dense(units=84, activation='relu', kernel_initializer='glorot_normal', bias_initializer='zeros'),\n",
    "    Dense(units=10, activation='softmax')\n",
    "])\n",
    "\n",
    "# Print model summary\n",
    "model.summary()\n",
    "\n",
    "# Compile the model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6a8f74f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "split_index = int(0.8 * len(X))\n",
    "X_train, X_test = X[:split_index], X[split_index:]\n",
    "y_train, y_test = y[:split_index], y[split_index:]\n",
    "\n",
    "# Convert labels to one-hot encoding\n",
    "num_classes = len(classes)\n",
    "y_train_one_hot = to_categorical(y_train, num_classes=num_classes)\n",
    "y_test_one_hot = to_categorical(y_test, num_classes=num_classes)\n",
    "\n",
    "# Define the model architecture\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, (3, 3), activation='relu', input_shape=(28, 28, 3)))\n",
    "model.add(MaxPooling2D((2, 2), strides=(2,2), padding = \"valid\"))\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D((2, 2), strides=(2,2), padding = \"valid\"))\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(X_train, y_train_one_hot, epochs=10, validation_split=0.2)\n",
    "\n",
    "# Evaluate the model\n",
    "test_loss, test_acc = model.evaluate(X_test, y_test_one_hot)\n",
    "print('Test accuracy:', test_acc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76aed811",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print('Test accuracy:', test_acc)\n",
    "print('Test loss', test_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dda6145",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(Xtrain.shape)\n",
    "print(model.input_shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1276c7ca",
   "metadata": {},
   "source": [
    "## Examine the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd82244d",
   "metadata": {},
   "outputs": [],
   "source": [
    "history.history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "551618db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot loss and accuracy curves\n",
    "pd.DataFrame(data=history.history).plot()\n",
    "plt.grid(True)\n",
    "plt.xlabel('epochs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24ac1f94",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image\n",
    "from tensorflow.keras.utils import plot_model\n",
    "\n",
    "# Visualize the layers of the model in 2D\n",
    "plot_model(model, to_file='model_plot.png', show_shapes=True, show_layer_names=True, expand_nested=True, rankdir='TB', dpi=96)\n",
    "\n",
    "# Display the plot in Jupyter Notebook\n",
    "Image(filename='model_plot.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6822fd16",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## Train the model with Tensorboard\n",
    "from keras.callbacks import TensorBoard\n",
    "tensorboard = TensorBoard(log_dir='./logs', histogram_freq=1, write_graph=True, write_images=True)\n",
    "history = model.fit(Xtrain, ytrain_cat, batch_size=28, epochs=10, validation_split=0.2, callbacks=[tensorboard])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc7a8772",
   "metadata": {},
   "outputs": [],
   "source": [
    "!kill 6006 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e65d423b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the TensorBoard notebook extension\n",
    "%load_ext tensorboard\n",
    "\n",
    "# Start TensorBoard\n",
    "%tensorboard --logdir logs\n",
    "#%reload_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ea46cd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Visualize the model architecture\n",
    "plot_model(model, show_shapes=True, show_layer_names=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4f94652",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c98fec5b",
   "metadata": {},
   "source": [
    " ## Pre-trained Networks\n",
    " Resnet50\n",
    " \n",
    "  Initialize the model\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63befd21",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications.resnet50 import ResNet50,decode_predictions,preprocess_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96ee30f5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model = ResNet50()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c4b21ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f40d854",
   "metadata": {},
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "\n",
    "def batch_prediction(base_path):\n",
    "    image_paths = glob(base_path + '/*.jpg')\n",
    "    num_images = min(len(image_paths), 6) # ensure that at most 6 subplots are created\n",
    "    for i in range(num_images):\n",
    "        img_path = image_paths[i]\n",
    "        # read and preprocess\n",
    "        pic = keras.preprocessing.image.load_img(img_path, target_size=(224, 224))\n",
    "        numpy_image = np.array(pic)\n",
    "        image_batch = np.expand_dims(numpy_image, axis=0)\n",
    "        processed_image = preprocess_input(image_batch)\n",
    "        \n",
    "        # predict\n",
    "        predictions = model.predict(processed_image)\n",
    "        label = decode_predictions(predictions)\n",
    "        \n",
    "        # plot\n",
    "       \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d99d9c65",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7208cdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from keras.applications.imagenet_utils import decode_predictions\n",
    "\n",
    "def batch_prediction(base_path, model):\n",
    "    \n",
    "    image_paths = glob(base_path + '/*.png')\n",
    "\n",
    "    num_images = max(min(len(image_paths), 6), 1) # ensure that at least one subplot is created\n",
    "\n",
    "    fig, axs = plt.subplots(1, num_images, figsize=(15, 5))\n",
    "\n",
    "    for i in range(num_images):\n",
    "\n",
    "        img_path = image_paths[i]\n",
    "\n",
    "        print(img_path)\n",
    "\n",
    "        # read and preprocess\n",
    "\n",
    "        pic = keras.preprocessing.image.load_img(img_path, target_size=(224, 224))\n",
    "\n",
    "        numpy_image = np.array(pic)\n",
    "\n",
    "        image_batch = np.expand_dims(numpy_image, axis=0)\n",
    "\n",
    "        processed_image = preprocess_input(image_batch)\n",
    "\n",
    "        \n",
    "\n",
    "        # predict\n",
    "\n",
    "        predictions = model.predict(processed_image)\n",
    "\n",
    "        label = decode_predictions(predictions)\n",
    "\n",
    "        label = label[0][0] # get the top prediction\n",
    "\n",
    "        \n",
    "\n",
    "        # plot\n",
    "\n",
    "        axs[i].imshow(pic)\n",
    "\n",
    "        axs[i].axis('off')\n",
    "\n",
    "        axs[i].set_title(label[1] + ': ' + str(round(label[2]*100, 2)) + '%')\n",
    "\n",
    "        \n",
    "\n",
    "        plt.show()\n",
    "\n",
    "        num_images = max(min(len(image_paths), 6), 1)\n",
    "\n",
    "        print(f\"Number of images to display: {num_images}\")\n",
    "\n",
    "        fig, axs = plt.subplots(1, num_images, figsize=(15, 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d29cbd9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "batch_prediction(base_path, model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0a65629f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.applications.mobilenet import MobileNet, decode_predictions, preprocess_input\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed86cad6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.applications.mobilenet import MobileNet, decode_predictions, preprocess_input\n",
    "\n",
    "# resize images to 224x224\n",
    "X_resized = tf.image.resize(X, (224, 224))\n",
    "mdl = MobileNet()  # download (on `ImageNet` pretrained) model \n",
    "# predict on resized images\n",
    "pred = mdl.predict(X_resized)\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "\n",
    "# Load the image\n",
    "\n",
    "# Resize the image to 224x224\n",
    "image = image.resize((224, 224))\n",
    "\n",
    "# Convert the image to a numpy array\n",
    "image_array = np.array(image)\n",
    "\n",
    "# Normalize the image array\n",
    "image_array = image_array.astype('float32') / 255.\n",
    "\n",
    "# Subtract the mean RGB values of ImageNet dataset from the image array\n",
    "mean = np.array([0.485, 0.456, 0.406])\n",
    "std = np.array([0.229, 0.224, 0.225])\n",
    "image_array = (image_array - mean) / std\n",
    "\n",
    "# Add a batch dimension to the image array\n",
    "image_array = np.expand_dims(image_array, axis=0)\n",
    "\n",
    "print(pred.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ddbb810",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = mdl.predict(X)\n",
    "pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4e29f1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "decode_predictions(pred) # make these preds \"human-readable\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59cff4c3",
   "metadata": {},
   "source": [
    "#### Check what is really in the image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9bbccf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(img);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d09f34a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11e6d707",
   "metadata": {},
   "outputs": [],
   "source": [
    "tk.preprocessing.i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3a793438",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the preprocessing function that should be applied to all images\n",
    "data_gen = tk.preprocessing.image.ImageDataGenerator(   # loads data in batches from disk\n",
    "    preprocessing_function=preprocess_input,\n",
    "    # fill_mode='nearest',\n",
    "    rotation_range=20,                               # rotate image by a random degree between -20 and 20\n",
    "    # width_shift_range=0.2,                         # shift image horizontally \n",
    "    # height_shift_range=0.2,                        # shift image vertically \n",
    "    # horizontal_flip=True,                          # randomly flip image horizontally\n",
    "    zoom_range=0.5,                                  # apply zoom transformation using zoom factor between 0.5 and 1.5\n",
    "    # shear_range=0.2                                # shear rotates pics, but makes them be in trapezoids (as opposed to squares)\n",
    "    validation_split=0.2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dc443703",
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = ['Blue_mug', 'mobile', 'Red_mug', 'Rose', 'empty', 'apple', 'biketool_mm', 'bodycream_test_ss', 'bodycream_train_ss', 'Bottle_gk',\n",
    "          'bottle_mw_test', 'bottle_mw_train', 'bottle_rbk','bottle_test_ss', 'bottle_train_ss', 'chris_bottle', 'chris_empty', 'crista_bottle',\n",
    "          'empty_crista', 'helge_scarf', 'helge_empty', 'plant_rbk', 'moritz_bottle','lighter_mm','him_teacup', 'helge_mouse',\n",
    "          'headphone_rbk','empty_train_ss', 'Naz_bottle']\n",
    "\n",
    "base_path = '.\\\\data\\\\'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4f09b3db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3275 images belonging to 29 classes.\n"
     ]
    }
   ],
   "source": [
    "# a generator that returns batches of X and y arrays\n",
    "train_data_gen = data_gen.flow_from_directory(      # points to dir where data lives\n",
    "        directory=base_path,\n",
    "        class_mode=\"categorical\",\n",
    "        classes=classes,\n",
    "        batch_size=64,\n",
    "        target_size=(224, 224),\n",
    "    subset='training'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "24dcfb98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 811 images belonging to 29 classes.\n"
     ]
    }
   ],
   "source": [
    "val_data_gen = data_gen.flow_from_directory(\n",
    "        directory=base_path,\n",
    "        class_mode=\"categorical\",\n",
    "        classes=classes,\n",
    "        batch_size=64,\n",
    "        target_size=(224, 224),\n",
    "    subset='validation'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d994957a",
   "metadata": {},
   "outputs": [],
   "source": [
    "classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68eb5a6d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_data_gen.class_indices"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cc733bb",
   "metadata": {},
   "source": [
    "## Create CNN Model as Base Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edec59a5",
   "metadata": {},
   "source": [
    "### 1. Select the convolutional base "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b666d409",
   "metadata": {},
   "source": [
    "#### Using MobileNet pretrained network for transfer learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5f0e0eba",
   "metadata": {},
   "outputs": [],
   "source": [
    "K.clear_session()\n",
    "base_model = MobileNet(\n",
    "    weights='imagenet',\n",
    "    include_top=False,                          # keep convolutional layers only\n",
    "    input_shape=(224, 224, 3)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "432fe79e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"mobilenet_1.00_224\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 224, 224, 3)]     0         \n",
      "                                                                 \n",
      " conv1 (Conv2D)              (None, 112, 112, 32)      864       \n",
      "                                                                 \n",
      " conv1_bn (BatchNormalizatio  (None, 112, 112, 32)     128       \n",
      " n)                                                              \n",
      "                                                                 \n",
      " conv1_relu (ReLU)           (None, 112, 112, 32)      0         \n",
      "                                                                 \n",
      " conv_dw_1 (DepthwiseConv2D)  (None, 112, 112, 32)     288       \n",
      "                                                                 \n",
      " conv_dw_1_bn (BatchNormaliz  (None, 112, 112, 32)     128       \n",
      " ation)                                                          \n",
      "                                                                 \n",
      " conv_dw_1_relu (ReLU)       (None, 112, 112, 32)      0         \n",
      "                                                                 \n",
      " conv_pw_1 (Conv2D)          (None, 112, 112, 64)      2048      \n",
      "                                                                 \n",
      " conv_pw_1_bn (BatchNormaliz  (None, 112, 112, 64)     256       \n",
      " ation)                                                          \n",
      "                                                                 \n",
      " conv_pw_1_relu (ReLU)       (None, 112, 112, 64)      0         \n",
      "                                                                 \n",
      " conv_pad_2 (ZeroPadding2D)  (None, 113, 113, 64)      0         \n",
      "                                                                 \n",
      " conv_dw_2 (DepthwiseConv2D)  (None, 56, 56, 64)       576       \n",
      "                                                                 \n",
      " conv_dw_2_bn (BatchNormaliz  (None, 56, 56, 64)       256       \n",
      " ation)                                                          \n",
      "                                                                 \n",
      " conv_dw_2_relu (ReLU)       (None, 56, 56, 64)        0         \n",
      "                                                                 \n",
      " conv_pw_2 (Conv2D)          (None, 56, 56, 128)       8192      \n",
      "                                                                 \n",
      " conv_pw_2_bn (BatchNormaliz  (None, 56, 56, 128)      512       \n",
      " ation)                                                          \n",
      "                                                                 \n",
      " conv_pw_2_relu (ReLU)       (None, 56, 56, 128)       0         \n",
      "                                                                 \n",
      " conv_dw_3 (DepthwiseConv2D)  (None, 56, 56, 128)      1152      \n",
      "                                                                 \n",
      " conv_dw_3_bn (BatchNormaliz  (None, 56, 56, 128)      512       \n",
      " ation)                                                          \n",
      "                                                                 \n",
      " conv_dw_3_relu (ReLU)       (None, 56, 56, 128)       0         \n",
      "                                                                 \n",
      " conv_pw_3 (Conv2D)          (None, 56, 56, 128)       16384     \n",
      "                                                                 \n",
      " conv_pw_3_bn (BatchNormaliz  (None, 56, 56, 128)      512       \n",
      " ation)                                                          \n",
      "                                                                 \n",
      " conv_pw_3_relu (ReLU)       (None, 56, 56, 128)       0         \n",
      "                                                                 \n",
      " conv_pad_4 (ZeroPadding2D)  (None, 57, 57, 128)       0         \n",
      "                                                                 \n",
      " conv_dw_4 (DepthwiseConv2D)  (None, 28, 28, 128)      1152      \n",
      "                                                                 \n",
      " conv_dw_4_bn (BatchNormaliz  (None, 28, 28, 128)      512       \n",
      " ation)                                                          \n",
      "                                                                 \n",
      " conv_dw_4_relu (ReLU)       (None, 28, 28, 128)       0         \n",
      "                                                                 \n",
      " conv_pw_4 (Conv2D)          (None, 28, 28, 256)       32768     \n",
      "                                                                 \n",
      " conv_pw_4_bn (BatchNormaliz  (None, 28, 28, 256)      1024      \n",
      " ation)                                                          \n",
      "                                                                 \n",
      " conv_pw_4_relu (ReLU)       (None, 28, 28, 256)       0         \n",
      "                                                                 \n",
      " conv_dw_5 (DepthwiseConv2D)  (None, 28, 28, 256)      2304      \n",
      "                                                                 \n",
      " conv_dw_5_bn (BatchNormaliz  (None, 28, 28, 256)      1024      \n",
      " ation)                                                          \n",
      "                                                                 \n",
      " conv_dw_5_relu (ReLU)       (None, 28, 28, 256)       0         \n",
      "                                                                 \n",
      " conv_pw_5 (Conv2D)          (None, 28, 28, 256)       65536     \n",
      "                                                                 \n",
      " conv_pw_5_bn (BatchNormaliz  (None, 28, 28, 256)      1024      \n",
      " ation)                                                          \n",
      "                                                                 \n",
      " conv_pw_5_relu (ReLU)       (None, 28, 28, 256)       0         \n",
      "                                                                 \n",
      " conv_pad_6 (ZeroPadding2D)  (None, 29, 29, 256)       0         \n",
      "                                                                 \n",
      " conv_dw_6 (DepthwiseConv2D)  (None, 14, 14, 256)      2304      \n",
      "                                                                 \n",
      " conv_dw_6_bn (BatchNormaliz  (None, 14, 14, 256)      1024      \n",
      " ation)                                                          \n",
      "                                                                 \n",
      " conv_dw_6_relu (ReLU)       (None, 14, 14, 256)       0         \n",
      "                                                                 \n",
      " conv_pw_6 (Conv2D)          (None, 14, 14, 512)       131072    \n",
      "                                                                 \n",
      " conv_pw_6_bn (BatchNormaliz  (None, 14, 14, 512)      2048      \n",
      " ation)                                                          \n",
      "                                                                 \n",
      " conv_pw_6_relu (ReLU)       (None, 14, 14, 512)       0         \n",
      "                                                                 \n",
      " conv_dw_7 (DepthwiseConv2D)  (None, 14, 14, 512)      4608      \n",
      "                                                                 \n",
      " conv_dw_7_bn (BatchNormaliz  (None, 14, 14, 512)      2048      \n",
      " ation)                                                          \n",
      "                                                                 \n",
      " conv_dw_7_relu (ReLU)       (None, 14, 14, 512)       0         \n",
      "                                                                 \n",
      " conv_pw_7 (Conv2D)          (None, 14, 14, 512)       262144    \n",
      "                                                                 \n",
      " conv_pw_7_bn (BatchNormaliz  (None, 14, 14, 512)      2048      \n",
      " ation)                                                          \n",
      "                                                                 \n",
      " conv_pw_7_relu (ReLU)       (None, 14, 14, 512)       0         \n",
      "                                                                 \n",
      " conv_dw_8 (DepthwiseConv2D)  (None, 14, 14, 512)      4608      \n",
      "                                                                 \n",
      " conv_dw_8_bn (BatchNormaliz  (None, 14, 14, 512)      2048      \n",
      " ation)                                                          \n",
      "                                                                 \n",
      " conv_dw_8_relu (ReLU)       (None, 14, 14, 512)       0         \n",
      "                                                                 \n",
      " conv_pw_8 (Conv2D)          (None, 14, 14, 512)       262144    \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                 \n",
      " conv_pw_8_bn (BatchNormaliz  (None, 14, 14, 512)      2048      \n",
      " ation)                                                          \n",
      "                                                                 \n",
      " conv_pw_8_relu (ReLU)       (None, 14, 14, 512)       0         \n",
      "                                                                 \n",
      " conv_dw_9 (DepthwiseConv2D)  (None, 14, 14, 512)      4608      \n",
      "                                                                 \n",
      " conv_dw_9_bn (BatchNormaliz  (None, 14, 14, 512)      2048      \n",
      " ation)                                                          \n",
      "                                                                 \n",
      " conv_dw_9_relu (ReLU)       (None, 14, 14, 512)       0         \n",
      "                                                                 \n",
      " conv_pw_9 (Conv2D)          (None, 14, 14, 512)       262144    \n",
      "                                                                 \n",
      " conv_pw_9_bn (BatchNormaliz  (None, 14, 14, 512)      2048      \n",
      " ation)                                                          \n",
      "                                                                 \n",
      " conv_pw_9_relu (ReLU)       (None, 14, 14, 512)       0         \n",
      "                                                                 \n",
      " conv_dw_10 (DepthwiseConv2D  (None, 14, 14, 512)      4608      \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv_dw_10_bn (BatchNormali  (None, 14, 14, 512)      2048      \n",
      " zation)                                                         \n",
      "                                                                 \n",
      " conv_dw_10_relu (ReLU)      (None, 14, 14, 512)       0         \n",
      "                                                                 \n",
      " conv_pw_10 (Conv2D)         (None, 14, 14, 512)       262144    \n",
      "                                                                 \n",
      " conv_pw_10_bn (BatchNormali  (None, 14, 14, 512)      2048      \n",
      " zation)                                                         \n",
      "                                                                 \n",
      " conv_pw_10_relu (ReLU)      (None, 14, 14, 512)       0         \n",
      "                                                                 \n",
      " conv_dw_11 (DepthwiseConv2D  (None, 14, 14, 512)      4608      \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv_dw_11_bn (BatchNormali  (None, 14, 14, 512)      2048      \n",
      " zation)                                                         \n",
      "                                                                 \n",
      " conv_dw_11_relu (ReLU)      (None, 14, 14, 512)       0         \n",
      "                                                                 \n",
      " conv_pw_11 (Conv2D)         (None, 14, 14, 512)       262144    \n",
      "                                                                 \n",
      " conv_pw_11_bn (BatchNormali  (None, 14, 14, 512)      2048      \n",
      " zation)                                                         \n",
      "                                                                 \n",
      " conv_pw_11_relu (ReLU)      (None, 14, 14, 512)       0         \n",
      "                                                                 \n",
      " conv_pad_12 (ZeroPadding2D)  (None, 15, 15, 512)      0         \n",
      "                                                                 \n",
      " conv_dw_12 (DepthwiseConv2D  (None, 7, 7, 512)        4608      \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv_dw_12_bn (BatchNormali  (None, 7, 7, 512)        2048      \n",
      " zation)                                                         \n",
      "                                                                 \n",
      " conv_dw_12_relu (ReLU)      (None, 7, 7, 512)         0         \n",
      "                                                                 \n",
      " conv_pw_12 (Conv2D)         (None, 7, 7, 1024)        524288    \n",
      "                                                                 \n",
      " conv_pw_12_bn (BatchNormali  (None, 7, 7, 1024)       4096      \n",
      " zation)                                                         \n",
      "                                                                 \n",
      " conv_pw_12_relu (ReLU)      (None, 7, 7, 1024)        0         \n",
      "                                                                 \n",
      " conv_dw_13 (DepthwiseConv2D  (None, 7, 7, 1024)       9216      \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv_dw_13_bn (BatchNormali  (None, 7, 7, 1024)       4096      \n",
      " zation)                                                         \n",
      "                                                                 \n",
      " conv_dw_13_relu (ReLU)      (None, 7, 7, 1024)        0         \n",
      "                                                                 \n",
      " conv_pw_13 (Conv2D)         (None, 7, 7, 1024)        1048576   \n",
      "                                                                 \n",
      " conv_pw_13_bn (BatchNormali  (None, 7, 7, 1024)       4096      \n",
      " zation)                                                         \n",
      "                                                                 \n",
      " conv_pw_13_relu (ReLU)      (None, 7, 7, 1024)        0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 3,228,864\n",
      "Trainable params: 3,206,976\n",
      "Non-trainable params: 21,888\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "base_model.summary()                            # as expected...see above"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75d5a0fc",
   "metadata": {},
   "source": [
    "#### Freeze the weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c1e54ba2",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model.trainable = False  # we don't want to train the base model, since this would destroy filters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52626df9",
   "metadata": {},
   "source": [
    "#### Build your \"individualized\" architecture for \"top-layers\"\n",
    "###### Add your own dense layers on top"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b21d7af8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "29"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8669620d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tk.models.Sequential()\n",
    "model.add(base_model)\n",
    "model.add(Flatten())  \n",
    "model.add(Dense(100, activation='relu'))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Dense(len(classes), activation='softmax')) # TODO; Final layer with a length of 2, and softmax activation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "73405040",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " mobilenet_1.00_224 (Functio  (None, 7, 7, 1024)       3228864   \n",
      " nal)                                                            \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 50176)             0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 100)               5017700   \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 100)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 29)                2929      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 8,249,493\n",
      "Trainable params: 5,020,629\n",
      "Non-trainable params: 3,228,864\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()                 # Note \"non-trainable\" params..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f28e524",
   "metadata": {},
   "source": [
    "### 4. Compile and train!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cda17622",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=tk.optimizers.Adam(learning_rate=0.001),\n",
    "              loss=tk.losses.categorical_crossentropy, #TODO: why not binary x-entropy?\n",
    "              metrics=[tk.metrics.categorical_accuracy])\n",
    "\n",
    "# observe the validation loss and stop when it does not improve after 3 iterations\n",
    "callback = tk.callbacks.EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    min_delta=0.05,     # the minimum expected change in the metric used in order to be seen as an improvement\n",
    "    patience=3,         # number of epochs with no improvement needed for the model to stop\n",
    "    restore_best_weights=True,\n",
    "    mode='min'\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8017431b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "52/52 - 157s - loss: 2.6479 - categorical_accuracy: 0.4769 - val_loss: 0.7217 - val_categorical_accuracy: 0.7928 - 157s/epoch - 3s/step\n",
      "Epoch 2/20\n",
      "52/52 - 131s - loss: 0.8767 - categorical_accuracy: 0.7316 - val_loss: 0.4299 - val_categorical_accuracy: 0.8878 - 131s/epoch - 3s/step\n",
      "Epoch 3/20\n",
      "52/52 - 135s - loss: 0.5972 - categorical_accuracy: 0.8180 - val_loss: 0.2748 - val_categorical_accuracy: 0.9346 - 135s/epoch - 3s/step\n",
      "Epoch 4/20\n",
      "52/52 - 129s - loss: 0.4658 - categorical_accuracy: 0.8501 - val_loss: 0.3129 - val_categorical_accuracy: 0.9174 - 129s/epoch - 2s/step\n",
      "Epoch 5/20\n",
      "52/52 - 127s - loss: 0.3839 - categorical_accuracy: 0.8763 - val_loss: 0.2261 - val_categorical_accuracy: 0.9297 - 127s/epoch - 2s/step\n",
      "Epoch 6/20\n",
      "52/52 - 153s - loss: 0.3413 - categorical_accuracy: 0.8950 - val_loss: 0.1456 - val_categorical_accuracy: 0.9568 - 153s/epoch - 3s/step\n",
      "Epoch 7/20\n",
      "52/52 - 177s - loss: 0.2869 - categorical_accuracy: 0.9075 - val_loss: 0.1794 - val_categorical_accuracy: 0.9457 - 177s/epoch - 3s/step\n",
      "Epoch 8/20\n",
      "52/52 - 186s - loss: 0.2972 - categorical_accuracy: 0.9044 - val_loss: 0.2034 - val_categorical_accuracy: 0.9531 - 186s/epoch - 4s/step\n",
      "Epoch 9/20\n",
      "52/52 - 190s - loss: 0.2949 - categorical_accuracy: 0.9115 - val_loss: 0.1884 - val_categorical_accuracy: 0.9494 - 190s/epoch - 4s/step\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(train_data_gen,\n",
    "          verbose=2, \n",
    "          callbacks=[callback],\n",
    "          epochs=20,\n",
    "          validation_data=val_data_gen\n",
    "          )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0617c6b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history['loss'], label = 'Training Loss')\n",
    "plt.plot(history.history['val_loss'], label = 'Validation Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2fb28ff",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d4fce63",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
